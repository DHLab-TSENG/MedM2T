{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: LOS - Unimodality (Pretrained Encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "root_path = \"...\"\n",
    "\n",
    "from config import device, data_folder, log_folder\n",
    "import pickle\n",
    "task_dir = \"LOS\"\n",
    "data_folder+=task_dir+\"/\"\n",
    "log_folder+=task_dir+\"/\"\n",
    "\n",
    "from itertools import combinations,product\n",
    "from models.unimodal import create_unimodal_model\n",
    "from models.multimodal import create_multimodal_model\n",
    "from training_evaluation import run_kfolds\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.LOS.static import StaticLoader\n",
    "static_dataset_path = data_folder+\"/static.pkl\"\n",
    "if os.path.exists(static_dataset_path):\n",
    "    with open(static_dataset_path, \"rb\") as f:\n",
    "        static = pickle.load(f)\n",
    "else:\n",
    "    static = StaticLoader()\n",
    "    with open(static_dataset_path, \"wb\") as f:\n",
    "        pickle.dump(static, f)\n",
    "ids = static.get_ids()\n",
    "targets_df = static.get_targets()\n",
    "targets = targets_df.targets.values\n",
    "targets_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils.data_selection as stool\n",
    "kfolds_fpath = root_path+\"datasets/%s/kfolds.pkl\"%(task_dir)\n",
    "if os.path.exists(kfolds_fpath):\n",
    "    with open(kfolds_fpath, \"rb\") as f:\n",
    "        kfolds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_dataset = static.get_dataset() \n",
    "static_dataset_param = {\n",
    "    \"path\": static_dataset_path,\n",
    "    \"num\": len(static_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blocks.mlp import  MLP, MLPDecoderReg\n",
    "\n",
    "FEATS_NUM = len(static.feats_cols)\n",
    "\n",
    "EMBED_DIM = 512\n",
    "ENCODER_DROPOUT = 0.1\n",
    "DECODER_DROPOUT = 0.5\n",
    "\n",
    "\n",
    "#MLP\n",
    "MLP_param = {\n",
    "    \"in_dim\": FEATS_NUM,\n",
    "    \"hidden_dim\": [EMBED_DIM, EMBED_DIM],\n",
    "    \"drop_prob\": ENCODER_DROPOUT\n",
    "}\n",
    "\n",
    "#Setting Decoder\n",
    "MLP_Decoder_param = {\n",
    "    \"in_dim\": EMBED_DIM,\n",
    "    \"hidden_dim\": [EMBED_DIM//2],\n",
    "    \"out_dim\": 1,\n",
    "    \"drop_prob\": DECODER_DROPOUT\n",
    "}\n",
    "\n",
    "#Setting Training Parameters\n",
    "train_param = {\n",
    "    \"DATASET\": static_dataset_param,\n",
    "    \"MODEL_NAME\": \"static_unimodal\",\n",
    "    \"ENCODER_PARAM\": [MLP_param],\n",
    "    \"ENCODER_MODEL\": [MLP.__name__],\n",
    "    \"DECODER_PARAM\": MLP_Decoder_param,\n",
    "    \"DECODER_MODEL\": MLPDecoderReg.__name__,\n",
    "    \"BATCH_SIZE\": 128,\n",
    "    \"LR\": 0.01,\n",
    "    \"MAX_EPOCHS\": 20,\n",
    "    \"OPTIMIZER\": \"Adam\"\n",
    "}\n",
    "\n",
    "model = create_unimodal_model(train_param[\"ENCODER_MODEL\"], \n",
    "                            train_param[\"ENCODER_PARAM\"], \n",
    "                            train_param[\"DECODER_MODEL\"], \n",
    "                            train_param[\"DECODER_PARAM\"], device)\n",
    "\n",
    "log = run_kfolds(train_param, model, static_dataset, kfolds, log_folder=log_folder, classification=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.LOS.labs import LabsLoader\n",
    "labs_dataset_path = data_folder+\"/labs.pkl\"\n",
    "if os.path.exists(labs_dataset_path):\n",
    "    with open(labs_dataset_path, \"rb\") as f:\n",
    "        labs = pickle.load(f)\n",
    "else:\n",
    "    labs = LabsLoader(ids, targets)\n",
    "    with open(labs_dataset_path, \"wb\") as f:\n",
    "        pickle.dump(labs, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "labs_dataset = labs.get_dataset(only_valid=True)\n",
    "labs_ids = labs.get_ids(only_valid=True)\n",
    "\n",
    "labs_dataset_param = {\n",
    "    \"path\": labs_dataset_path,\n",
    "    \"only_valid\": True,\n",
    "    \"num\": len(labs_dataset)\n",
    "}\n",
    "\n",
    "#getting the labs kfolds(subsets of the kfolds, only with the valid labs)\n",
    "labs_kfolds = stool.get_sub_kfolds(ids, labs_ids, kfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blocks.embedding import TimeWinEmbedding\n",
    "from blocks.rnn import LSTM\n",
    "from blocks.mlp import  MLP, MLPDecoderReg\n",
    "from datasets.collate_fun import CreateCustomDataset, time_win_tokens_batch\n",
    "\n",
    "#get values/souces vocab numbers\n",
    "labs_val_vsize = int(labs.values_None_label+1)\n",
    "labs_src_vsize = int(labs.sources_None_label+1)\n",
    "print(labs_val_vsize, labs_src_vsize)\n",
    "\n",
    "EMBED_DIM = 512\n",
    "ENCODER_DROPOUT = 0.05\n",
    "DECODER_DROPOUT = 0.1\n",
    "\n",
    "TWEmbed_param = {\n",
    "    \"value_vocab_size\":labs_val_vsize, \n",
    "    \"source_vocab_size\":labs_src_vsize, \n",
    "    \"win_size\":labs.win_num, \n",
    "    \"embed_dim\":EMBED_DIM, \n",
    "    \"device\":device, \n",
    "    \"temporal_weighted\":False,\n",
    "    \"shared_embedding\":True\n",
    "}\n",
    "\n",
    "#BiLSTM\n",
    "LSTM_param = {\n",
    "    \"input_size\": EMBED_DIM,\n",
    "    \"hidden_size\": EMBED_DIM//2,\n",
    "    \"num_layers\": 2,\n",
    "    \"bidirectional\":True\n",
    "}\n",
    "\n",
    "#MLP\n",
    "MLP_param = {\n",
    "    \"in_dim\": EMBED_DIM,\n",
    "    \"hidden_dim\": [EMBED_DIM, EMBED_DIM],\n",
    "    \"drop_prob\": ENCODER_DROPOUT\n",
    "}\n",
    "\n",
    "#Setting Decoder\n",
    "#MLPDecoder\n",
    "MLP_decoder_param = {\n",
    "    \"in_dim\": EMBED_DIM,\n",
    "    \"out_dim\": targets_num,\n",
    "    \"hidden_dim\": [EMBED_DIM//2],\n",
    "    \"drop_prob\": DECODER_DROPOUT\n",
    "}\n",
    "\n",
    "collate_fn_params = [\n",
    "    {\"name\":time_win_tokens_batch.__name__, \"param\":{\"accum\":True,\"onset\":False}},\n",
    "    {\"name\":time_win_tokens_batch.__name__, \"param\":{\"accum\":True,\"onset\":False}},\n",
    "]\n",
    "\n",
    "#Setting Training Parameters\n",
    "train_param = {\n",
    "    \"DATASET\": labs_dataset_param,\n",
    "    \"MODEL_NAME\": \"labs_unimodal\",\n",
    "    \"ENCODER_PARAM\": [TWEmbed_param, LSTM_param, MLP_param],\n",
    "    \"ENCODER_MODEL\": [TimeWinEmbedding.__name__, LSTM.__name__, MLP.__name__],\n",
    "    \"DECODER_PARAM\": MLP_decoder_param,\n",
    "    \"DECODER_MODEL\": MLPDecoderReg.__name__,\n",
    "    \"BATCH_SIZE\": 128,\n",
    "    \"LR\": 0.0025,\n",
    "    \"MAX_EPOCHS\": 20,\n",
    "    \"OPTIMIZER\": \"Adam\",\n",
    "    \"COLLATE_FN_PARAMS\": collate_fn_params\n",
    "}\n",
    "\n",
    "model = create_unimodal_model(train_param[\"ENCODER_MODEL\"], \n",
    "                            train_param[\"ENCODER_PARAM\"], \n",
    "                            train_param[\"DECODER_MODEL\"], \n",
    "                            train_param[\"DECODER_PARAM\"], device)\n",
    "\n",
    "collate_batch = CreateCustomDataset(len(collate_fn_params), train_param[\"COLLATE_FN_PARAMS\"], classfication=False)\n",
    "log = run_kfolds(train_param, model, labs_dataset, labs_kfolds, collate_fun = collate_batch, log_folder=log_folder, classification=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vitals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Vitals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.LOS.vitalsigns import VitalsNumLoader\n",
    "vitals_segs_dataset_path = data_folder+\"/vitals_segs.pkl\"\n",
    "vitals_segs_win_size = 12\n",
    "vitals_segs_num = 24\n",
    "if os.path.exists(vitals_segs_dataset_path):\n",
    "    with open(vitals_segs_dataset_path, \"rb\") as f:\n",
    "        vitals_segs = pickle.load(f)\n",
    "else:\n",
    "    vitals_segs = VitalsNumLoader(ids, targets)\n",
    "    with open(vitals_segs_dataset_path, \"wb\") as f:\n",
    "        pickle.dump(vitals_segs, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "vitals_seg_dataset_param = {\n",
    "    \"path\": vitals_segs_dataset_path,\n",
    "    \"win_size\": vitals_segs_win_size,\n",
    "    \"segs_num\": vitals_segs_num,\n",
    "    \"only_valid\": True,\n",
    "    \"flatten\":True\n",
    "}\n",
    "\n",
    "#set segments parameters\n",
    "vitals_segs.set_seg_data(vitals_segs_win_size, vitals_segs_num)\n",
    "vitals_segs_dataset = vitals_segs.get_dataset(only_valid=vitals_seg_dataset_param[\"only_valid\"], \n",
    "                                              flatten=vitals_seg_dataset_param[\"flatten\"])\n",
    "\n",
    "vitals_num_ids = vitals_segs.get_ids(only_valid=vitals_seg_dataset_param[\"only_valid\"])\n",
    "vitals_seg_dataset_param[\"num\"] = len(vitals_segs_dataset)\n",
    "\n",
    "#get kfolds index of the flatten segments\n",
    "vitals_num_kfolds = stool.get_sub_kfolds(ids, vitals_num_ids, kfolds)\n",
    "vitals_segs_kfolds = []\n",
    "for _train_idx, _valid_idx, _test_idx in vitals_num_kfolds:\n",
    "    vitals_segs_kfolds.append([vitals_segs.get_flatten_idx(_train_idx), \n",
    "                               vitals_segs.get_flatten_idx(_valid_idx), \n",
    "                               vitals_segs.get_flatten_idx(_test_idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blocks.mlp import MLP, MLPDecoderReg\n",
    "from blocks.resnet import ResNet1d\n",
    "from blocks.attention import FeatureSelfAttn\n",
    "\n",
    "#for win12\n",
    "if vitals_segs_win_size == 12:\n",
    "    ATTEN_OUT_DIM = 8\n",
    "    EMBED_DIM = 128\n",
    "    LR = 0.0025\n",
    "\n",
    "#for win24\n",
    "if vitals_segs_win_size == 24:\n",
    "    ATTEN_OUT_DIM = 16\n",
    "    EMBED_DIM = 256\n",
    "    LR = 0.001\n",
    "\n",
    "FILTER_SIZE = [ATTEN_OUT_DIM*2, ATTEN_OUT_DIM*4]\n",
    "SEQ_LEN = [vitals_segs_win_size, vitals_segs_win_size//2]\n",
    "\n",
    "SelfAttn_param = {\n",
    "    \"embed_dim\":8,\n",
    "    \"num_heads\":4,\n",
    "    \"drop_prob\":0.05,\n",
    "    \"out_dim\":ATTEN_OUT_DIM\n",
    "}\n",
    "\n",
    "ResNet_param = {\n",
    "    \"input_dim\": (SelfAttn_param[\"out_dim\"], vitals_segs_win_size),\n",
    "    \"blocks_dim\": list(zip(FILTER_SIZE, SEQ_LEN)),\n",
    "    \"kernel_size\": 3,\n",
    "    \"dropout_rate\": 0.3\n",
    "}\n",
    "\n",
    "MLP_param = {\n",
    "    \"in_dim\": ResNet_param[\"blocks_dim\"][-1][0] * ResNet_param[\"blocks_dim\"][-1][1],\n",
    "    \"hidden_dim\": [EMBED_DIM],\n",
    "    \"drop_prob\": 0.1\n",
    "}\n",
    "\n",
    "MLP_decoder_param = {\n",
    "    \"in_dim\": MLP_param[\"hidden_dim\"][-1],\n",
    "    \"out_dim\": targets_num,\n",
    "    \"hidden_dim\": [MLP_param[\"hidden_dim\"][-1]//2],\n",
    "    \"drop_prob\": 0.25\n",
    "}\n",
    "\n",
    "#Setting Training Parameters\n",
    "train_param = {\n",
    "    \"DATASET\": vitals_seg_dataset_param,\n",
    "    \"MODEL_NAME\": \"vitals_segs_unimodal\",\n",
    "    \"ENCODER_PARAM\": [SelfAttn_param, ResNet_param, MLP_param],\n",
    "    \"ENCODER_MODEL\": [FeatureSelfAttn.__name__, ResNet1d.__name__, MLP.__name__],\n",
    "    \"DECODER_PARAM\": MLP_decoder_param,\n",
    "    \"DECODER_MODEL\": MLPDecoderReg.__name__,\n",
    "    \"BATCH_SIZE\": 128,\n",
    "    \"LR\": LR,\n",
    "    \"MAX_EPOCHS\": 20,\n",
    "    \"OPTIMIZER\": \"Adam\"\n",
    "}\n",
    "\n",
    "model = create_unimodal_model(train_param[\"ENCODER_MODEL\"], \n",
    "                            train_param[\"ENCODER_PARAM\"], \n",
    "                            train_param[\"DECODER_MODEL\"], \n",
    "                            train_param[\"DECODER_PARAM\"], device)\n",
    "\n",
    "log = run_kfolds(train_param, model, vitals_segs_dataset, vitals_segs_kfolds, log_folder=log_folder, classification=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.LOS.vitalsigns import VitalsNumLoader, multiscale_vitalsigns\n",
    "vitals_segs_dataset_path = data_folder+\"/vitals_segs.pkl\"\n",
    "vitals_segs_num = 24\n",
    "if os.path.exists(vitals_segs_dataset_path):\n",
    "    with open(vitals_segs_dataset_path, \"rb\") as f:\n",
    "        vitals_segs = pickle.load(f)\n",
    "else:\n",
    "    vitals_segs = VitalsNumLoader(ids, targets)\n",
    "    with open(vitals_segs_dataset_path, \"wb\") as f:\n",
    "        pickle.dump(vitals_segs, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "win_size_list = [12, 24]\n",
    "multiscale = []\n",
    "for vitals_segs_win_size in win_size_list:\n",
    "    vitals_segs.set_seg_data(vitals_segs_win_size, vitals_segs_num)\n",
    "    vitals_segs_dataset = vitals_segs.get_dataset(only_valid=True, flatten=False)\n",
    "    multiscale.append(vitals_segs_dataset)\n",
    "\n",
    "vitals_multiscale_dataset = multiscale_vitalsigns(multiscale[0], multiscale[1])\n",
    "\n",
    "vitals_multiscale_dataset_param = {\n",
    "    \"path\": vitals_segs_dataset_path,\n",
    "    \"win_size\": win_size_list,\n",
    "    \"segs_num\": vitals_segs_num,\n",
    "    \"only_valid\": True,\n",
    "    \"flatten\": False,\n",
    "    \"num\": len(vitals_multiscale_dataset)\n",
    "}\n",
    "\n",
    "vitals_num_kfolds = stool.get_sub_kfolds(ids, vitals_num_ids, kfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blocks.mlp import MLP, MLPDecoderReg\n",
    "from blocks.resnet import ResNet1d\n",
    "from models.unimodal import MultiScale\n",
    "\n",
    "k_models = True \n",
    "EMBED_DIM = 256\n",
    "\n",
    "MultiScale_param = {\n",
    "\"model_path_list\": [log_folder+\"/vitals_segs_unimodal/.../\",#win12\n",
    "                    log_folder+\"/vitals_segs_unimodal/.../\"], #win24\n",
    "\"model_list\":[],\n",
    "\"size_list\": win_size_list\n",
    "}\n",
    "\n",
    "#loading fold0 models\n",
    "for model_path in MultiScale_param[\"model_path_list\"]:\n",
    "    seg_model = torch.load(model_path+\"model_0.pth\", weights_only=False)\n",
    "    MultiScale_param[\"model_list\"].append(seg_model.encoder)\n",
    "\n",
    "seg_embeds_size = sum([model[-1].mlp[0].out_features for model in MultiScale_param[\"model_list\"]])\n",
    "FILTER_SIZE = [seg_embeds_size, seg_embeds_size//2]\n",
    "SEQ_LEN = [vitals_segs_num, vitals_segs_num//2]\n",
    "\n",
    "ResNet_param = {\n",
    "    \"input_dim\": (seg_embeds_size, vitals_segs_num),\n",
    "    \"blocks_dim\": list(zip(FILTER_SIZE, SEQ_LEN)),\n",
    "    \"kernel_size\": 3,\n",
    "    \"dropout_rate\": 0.3\n",
    "}\n",
    "\n",
    "MLP_param = {\n",
    "    \"in_dim\": ResNet_param[\"blocks_dim\"][-1][0] * ResNet_param[\"blocks_dim\"][-1][1],\n",
    "    \"hidden_dim\": [EMBED_DIM],\n",
    "    \"drop_prob\": 0.1\n",
    "}\n",
    "\n",
    "MLP_decoder_param = {\n",
    "    \"in_dim\": MLP_param[\"hidden_dim\"][-1],\n",
    "    \"out_dim\": targets_num,\n",
    "    \"hidden_dim\": [MLP_param[\"hidden_dim\"][-1]//2],\n",
    "    \"drop_prob\": 0.25\n",
    "}\n",
    "\n",
    "#Setting Training Parameters\n",
    "train_param = {\n",
    "    \"DATASET\": vitals_multiscale_dataset_param,\n",
    "    \"MODEL_NAME\": \"vitals_num_unimodal\",\n",
    "    \"ENCODER_PARAM\": [MultiScale_param, ResNet_param, MLP_param],\n",
    "    \"ENCODER_MODEL\": [MultiScale.__name__, ResNet1d.__name__, MLP.__name__],\n",
    "    \"DECODER_PARAM\": MLP_decoder_param,\n",
    "    \"DECODER_MODEL\": MLPDecoderReg.__name__,\n",
    "    \"BATCH_SIZE\": 128,\n",
    "    \"LR\": 0.0005,\n",
    "    \"MAX_EPOCHS\": 20,\n",
    "    \"OPTIMIZER\": \"Adam\"\n",
    "}\n",
    "\n",
    "#loading k models for each fold\n",
    "if k_models:\n",
    "    model = []\n",
    "    for i in range(len(kfolds)):\n",
    "        MultiScale_param[\"model_list\"] = []\n",
    "        for model_path in train_param[\"ENCODER_PARAM\"][0][\"model_path_list\"]:\n",
    "            seg_model = torch.load(model_path+\"model_%d.pth\"%(i), weights_only=False)\n",
    "            MultiScale_param[\"model_list\"].append(seg_model.encoder)\n",
    "\n",
    "        model_i = create_unimodal_model(train_param[\"ENCODER_MODEL\"], \n",
    "                                    train_param[\"ENCODER_PARAM\"], \n",
    "                                    train_param[\"DECODER_MODEL\"], \n",
    "                                    train_param[\"DECODER_PARAM\"], device)\n",
    "        model.append(model_i)\n",
    "else:\n",
    "    model = create_unimodal_model(train_param[\"ENCODER_MODEL\"], \n",
    "                                train_param[\"ENCODER_PARAM\"], \n",
    "                                train_param[\"DECODER_MODEL\"], \n",
    "                                train_param[\"DECODER_PARAM\"], device)\n",
    "\n",
    "del MultiScale_param[\"model_list\"]\n",
    "\n",
    "\n",
    "log = run_kfolds(train_param, model, vitals_multiscale_dataset, vitals_num_kfolds, log_folder=log_folder, classification=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.LOS.vitalsigns import VitalsCatLoader\n",
    "vitals_cat_dataset_path = data_folder+\"/vitals_cat.pkl\"\n",
    "if os.path.exists(vitals_cat_dataset_path):\n",
    "    with open(vitals_cat_dataset_path, \"rb\") as f:\n",
    "        vitals_cat = pickle.load(f)\n",
    "else:\n",
    "    vitals_cat = VitalsCatLoader(ids, targets)\n",
    "    with open(vitals_cat_dataset_path, \"wb\") as f:\n",
    "        pickle.dump(vitals_cat, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "vitals_cat_dataset = vitals_cat.get_dataset(only_valid=True)\n",
    "vitals_cat_ids = vitals_cat.get_ids(only_valid=True)\n",
    "\n",
    "vitals_cat_dataset_param = {\n",
    "    \"path\": vitals_cat_dataset_path,\n",
    "    \"only_valid\": True,\n",
    "    \"num\":len(vitals_cat_dataset)\n",
    "}\n",
    "\n",
    "vitals_cat_kfolds = stool.get_sub_kfolds(ids, vitals_cat_ids, kfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blocks.embedding import TimeWinEmbedding\n",
    "from blocks.rnn import LSTM\n",
    "from blocks.mlp import  MLP, MLPDecoderReg\n",
    "from datasets.collate_fun import CreateCustomDataset, time_win_tokens_batch\n",
    "\n",
    "vitals_val_vsize = int(vitals_cat.vals_None_label+1)\n",
    "vitals_src_vsize = int(vitals_cat.srcs_None_label+1)\n",
    "print(vitals_val_vsize, vitals_src_vsize)\n",
    "EMBED_DIM = 256\n",
    "\n",
    "TWEmbed_param = {\n",
    "    \"value_vocab_size\":vitals_val_vsize, \n",
    "    \"source_vocab_size\":vitals_src_vsize, \n",
    "    \"win_size\":vitals_cat.win_num, \n",
    "    \"embed_dim\":EMBED_DIM, \n",
    "    \"device\":device, \n",
    "    \"temporal_weighted\":False, \n",
    "    \"shared_embedding\":True\n",
    "}\n",
    "\n",
    "#BiLSTM\n",
    "LSTM_param = {\n",
    "    \"input_size\": EMBED_DIM,\n",
    "    \"hidden_size\": EMBED_DIM//2,\n",
    "    \"num_layers\": 2,\n",
    "    \"bidirectional\":True\n",
    "}\n",
    "\n",
    "MLP_param = {\n",
    "    \"in_dim\": EMBED_DIM,\n",
    "    \"hidden_dim\": [EMBED_DIM, EMBED_DIM],\n",
    "    \"drop_prob\": 0.1\n",
    "}\n",
    "\n",
    "MLP_decoder_param = {\n",
    "    \"in_dim\": EMBED_DIM,\n",
    "    \"out_dim\": targets_num,\n",
    "    \"hidden_dim\": [EMBED_DIM//2],\n",
    "    \"drop_prob\": 0.1\n",
    "}   \n",
    "\n",
    "collate_fn_params = [\n",
    "    {\"name\":time_win_tokens_batch.__name__, \"param\":{\"accum\":True,\"onset\":False}},\n",
    "    {\"name\":time_win_tokens_batch.__name__, \"param\":{\"accum\":True,\"onset\":False}},\n",
    "]\n",
    "\n",
    "#Setting Training Parameters\n",
    "train_param = {\n",
    "    \"DATASET\": vitals_cat_dataset_param,\n",
    "    \"MODEL_NAME\": \"vitals_cat_unimodal\",\n",
    "    \"ENCODER_PARAM\": [TWEmbed_param, LSTM_param, MLP_param],\n",
    "    \"ENCODER_MODEL\": [TimeWinEmbedding.__name__, LSTM.__name__, MLP.__name__],\n",
    "    \"DECODER_PARAM\": MLP_decoder_param,\n",
    "    \"DECODER_MODEL\": MLPDecoderReg.__name__,\n",
    "    \"BATCH_SIZE\": 128,\n",
    "    \"LR\": 0.001,\n",
    "    \"MAX_EPOCHS\": 20,\n",
    "    \"OPTIMIZER\": \"Adam\",\n",
    "    \"COLLATE_FN_PARAMS\": collate_fn_params\n",
    "}\n",
    "\n",
    "model = create_unimodal_model(train_param[\"ENCODER_MODEL\"], \n",
    "                            train_param[\"ENCODER_PARAM\"], \n",
    "                            train_param[\"DECODER_MODEL\"], \n",
    "                            train_param[\"DECODER_PARAM\"], device)\n",
    "\n",
    "collate_batch = CreateCustomDataset(len(collate_fn_params), train_param[\"COLLATE_FN_PARAMS\"], classfication=False)\n",
    "log = run_kfolds(train_param, model, vitals_cat_dataset, vitals_cat_kfolds, collate_fun=collate_batch, log_folder=log_folder, classification=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.LOS.ecg import ECGLoader\n",
    "ecg_dataset_path = data_folder+\"/ecg.pkl\"\n",
    "if os.path.exists(ecg_dataset_path):\n",
    "    with open(ecg_dataset_path, \"rb\") as f:\n",
    "        ecg = pickle.load(f)\n",
    "else:\n",
    "# if True:\n",
    "    ecg = ECGLoader(ids, targets)\n",
    "    with open(ecg_dataset_path, \"wb\") as f:\n",
    "        pickle.dump(ecg, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "ecg_ids = ecg.get_ids(only_valid=True)\n",
    "ecg_kfolds = stool.get_sub_kfolds(ids, ecg_ids, kfolds)\n",
    "ecg_sig_kfolds = []\n",
    "for _train_idx, _valid_idx, _test_idx in ecg_kfolds:\n",
    "    ecg_sig_kfolds.append([ecg.get_subi2ecgi(_train_idx, only_valid=True), \n",
    "                           ecg.get_subi2ecgi(_valid_idx, only_valid=True),\n",
    "                           ecg.get_subi2ecgi(_test_idx, only_valid=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_note_dataset = ecg.get_ecg_dataset(type=\"tokens\")\n",
    "ecg_note_dataset_param = {\n",
    "    \"path\": ecg_dataset_path,\n",
    "    \"num\": len(ecg_note_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blocks.embedding import Embedding\n",
    "from blocks.mlp import MLP, MLPDecoderReg\n",
    "from datasets.collate_fun import CreateCustomDataset, tokens_batch\n",
    "ecg_vocab_size = int(ecg.ecg_statement_None_label+1)\n",
    "EMBED_DIM = 256\n",
    "\n",
    "Embedding_param = {\n",
    "    \"vocab_size\": ecg_vocab_size,\n",
    "    \"embed_size\": EMBED_DIM,\n",
    "}\n",
    "\n",
    "MLP_param = {\n",
    "    \"in_dim\": EMBED_DIM,\n",
    "    \"hidden_dim\": [EMBED_DIM, EMBED_DIM],\n",
    "    \"drop_prob\": 0.25\n",
    "}\n",
    "\n",
    "MLP_decoder_param = {\n",
    "    \"in_dim\": EMBED_DIM,\n",
    "    \"out_dim\": targets_num,\n",
    "    \"hidden_dim\": [EMBED_DIM//2],\n",
    "    \"drop_prob\": 0.25\n",
    "}\n",
    "\n",
    "collate_fn_params = [{\"name\": tokens_batch.__name__, \"param\": {\"accum\": False, \"onset\": True}}]\n",
    "\n",
    "#Setting Training Parameters\n",
    "train_param = {\n",
    "    \"DATASET\": ecg_note_dataset_param,\n",
    "    \"MODEL_NAME\": \"ecg_note_unimodal\",\n",
    "    \"ENCODER_PARAM\": [Embedding_param, MLP_param],\n",
    "    \"ENCODER_MODEL\": [Embedding.__name__, MLP.__name__],\n",
    "    \"DECODER_PARAM\": MLP_decoder_param,\n",
    "    \"DECODER_MODEL\": MLPDecoderReg.__name__,\n",
    "    \"BATCH_SIZE\": 128,\n",
    "    \"LR\": 0.001,\n",
    "    \"MAX_EPOCHS\": 20,\n",
    "    \"OPTIMIZER\": \"Adam\",\n",
    "    \"COLLATE_FN_PARAMS\": collate_fn_params\n",
    "}\n",
    "\n",
    "model = create_unimodal_model(train_param[\"ENCODER_MODEL\"],\n",
    "                            train_param[\"ENCODER_PARAM\"],\n",
    "                            train_param[\"DECODER_MODEL\"],\n",
    "                            train_param[\"DECODER_PARAM\"], device)\n",
    "\n",
    "collate_batch = CreateCustomDataset(len(collate_fn_params), train_param[\"COLLATE_FN_PARAMS\"], classfication=False)   \n",
    "log = run_kfolds(train_param, model, ecg_note_dataset, ecg_sig_kfolds, log_folder=log_folder, collate_fun=collate_batch, classification=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_sig_dataset = ecg.get_ecg_dataset(type=\"sig\")\n",
    "ecg_sig_dataset_param = {\n",
    "    \"path\": ecg_dataset_path,\n",
    "    \"num\": len(ecg_sig_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blocks.resnet import ResNet1d\n",
    "from blocks.mlp import MLP, MLPDecoderReg\n",
    "EMBED_DIM = 640\n",
    "ECG_CHANNEL = 12\n",
    "SIG_LEN = 640\n",
    "FILTER_SIZE = [64, 128, 196, 256, 320]\n",
    "SEQ_LEN = [640, 320, 160, 40, 20]\n",
    "\n",
    "ResNet_param = {\n",
    "    \"input_dim\": (ECG_CHANNEL, SIG_LEN),\n",
    "    \"blocks_dim\": list(zip(FILTER_SIZE, SEQ_LEN)),\n",
    "    \"kernel_size\": 5,\n",
    "    \"dropout_rate\": 0.3\n",
    "}\n",
    "\n",
    "MLP_param = {\n",
    "    \"in_dim\": FILTER_SIZE[-1] * SEQ_LEN[-1],\n",
    "    \"hidden_dim\": [EMBED_DIM],\n",
    "    \"drop_prob\": 0.1\n",
    "}\n",
    "\n",
    "MLP_decoder_param = {\n",
    "    \"in_dim\": MLP_param[\"hidden_dim\"][-1],\n",
    "    \"out_dim\": targets_num,\n",
    "    \"hidden_dim\": [EMBED_DIM//2],\n",
    "    \"drop_prob\": 0.1\n",
    "}\n",
    "\n",
    "train_param = {\n",
    "    \"DATASET\": ecg_sig_dataset_param,\n",
    "    \"MODEL_NAME\": \"ecg_sig_unimodal\",\n",
    "    \"ENCODER_PARAM\": [ResNet_param, MLP_param],\n",
    "    \"ENCODER_MODEL\": [ResNet1d.__name__, MLP.__name__],\n",
    "    \"DECODER_PARAM\": MLP_decoder_param,\n",
    "    \"DECODER_MODEL\": MLPDecoderReg.__name__,\n",
    "    \"BATCH_SIZE\": 128,\n",
    "    \"LR\": 0.0005,\n",
    "    \"MAX_EPOCHS\": 20,\n",
    "    \"OPTIMIZER\": \"Adam\"\n",
    "}\n",
    "\n",
    "model = create_unimodal_model(train_param[\"ENCODER_MODEL\"],\n",
    "                                train_param[\"ENCODER_PARAM\"],\n",
    "                                train_param[\"DECODER_MODEL\"],\n",
    "                                train_param[\"DECODER_PARAM\"], device)\n",
    "\n",
    "log = run_kfolds(train_param, model, ecg_sig_dataset, ecg_sig_kfolds[:1], log_folder=log_folder, classification=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_feats_dataset = ecg.get_ecg_dataset(type=\"feats\")\n",
    "ecg_feats_dataset_param = {\n",
    "    \"path\": ecg_dataset_path,\n",
    "    \"num\": len(ecg_feats_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blocks.mlp import MLP, MLPDecoderReg\n",
    "\n",
    "FEATS_NUM = ecg.ecg_feats.shape[1]\n",
    "EMBED_DIM = 256\n",
    "\n",
    "MLP_param = {\n",
    "    \"in_dim\": FEATS_NUM,\n",
    "    \"hidden_dim\": [EMBED_DIM],\n",
    "    \"drop_prob\": 0.05\n",
    "}\n",
    "\n",
    "MLP_decoder_param = {\n",
    "    \"in_dim\": MLP_param[\"hidden_dim\"][-1],\n",
    "    \"out_dim\": targets_num,\n",
    "    \"hidden_dim\": [EMBED_DIM//2],\n",
    "    \"drop_prob\": 0.05\n",
    "}\n",
    "\n",
    "train_param = {\n",
    "    \"DATASET\": ecg_feats_dataset_param,\n",
    "    \"MODEL_NAME\": \"ecg_feats_unimodal\",\n",
    "    \"ENCODER_PARAM\": [MLP_param],\n",
    "    \"ENCODER_MODEL\": [MLP.__name__],\n",
    "    \"DECODER_PARAM\": MLP_decoder_param,\n",
    "    \"DECODER_MODEL\": MLPDecoderReg.__name__,\n",
    "    \"BATCH_SIZE\": 128,\n",
    "    \"LR\": 0.001,\n",
    "    \"MAX_EPOCHS\": 20,\n",
    "    \"OPTIMIZER\": \"Adam\"\n",
    "}\n",
    "\n",
    "model = create_unimodal_model(train_param[\"ENCODER_MODEL\"],\n",
    "                                train_param[\"ENCODER_PARAM\"],\n",
    "                                train_param[\"DECODER_MODEL\"],\n",
    "                                train_param[\"DECODER_PARAM\"], device)\n",
    "\n",
    "\n",
    "log = run_kfolds(train_param, model, ecg_feats_dataset, ecg_kfolds, log_folder=log_folder,classification=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ECG Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets.LOS.ecg import ECGFusionDataset\n",
    "\n",
    "only_last = True\n",
    "if only_last:\n",
    "    all_ecg_ids = ecg.get_ecg_ids()\n",
    "    all_ecg_ids = list(all_ecg_ids)\n",
    "    last_ecg_index = []\n",
    "    for id in ecg_ids:\n",
    "        last_ecg_id = ecg.subject_dict[id][\"ecg_id\"][-1]\n",
    "        last_ecg_index.append(all_ecg_ids.index(last_ecg_id))\n",
    "    \n",
    "    ecg_fusion_dataset = ECGFusionDataset(ecg.ecg_signal[last_ecg_index], ecg.ecg_feats[last_ecg_index], \n",
    "                                          ecg.ecg_statement_tokens[last_ecg_index], ecg.ecg_targets[last_ecg_index], \n",
    "                                          ecg.ecg_ids[last_ecg_index])\n",
    "\n",
    "else:\n",
    "    ecg_fusion_dataset = ecg.get_ecg_dataset(type=\"fusion\")\n",
    "\n",
    "ecg_fusion_dataset_param = {\n",
    "    \"path\": ecg_dataset_path,\n",
    "    \"num\": len(ecg_fusion_dataset),\n",
    "    \"last\": only_last\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.multimodal import BiModalAttn\n",
    "from blocks.mlp import MLPDecoderReg, MLP\n",
    "from datasets.collate_fun import CreateCustomDataset, tokens_batch, basic_collate_fn\n",
    "import math\n",
    "\n",
    "k_models = True\n",
    "EMBED_DIM = 256\n",
    "\n",
    "encoders_i = [0,1,2]\n",
    "\n",
    "ecg_sig_model_param = {\n",
    "    \"model_path\": log_folder+\"/ecg_sig_unimodal/.../\",\n",
    "    \"out_dim\": 640\n",
    "}\n",
    "\n",
    "ecg_feats_model_param = {\n",
    "    \"model_path\": log_folder+\"/ecg_feats_unimodal/.../\",\n",
    "    \"out_dim\": 256\n",
    "}\n",
    "\n",
    "ecg_note_model_param = {\n",
    "    \"model_path\": log_folder+\"/ecg_note_unimodal/.../\",\n",
    "    \"out_dim\": 256\n",
    "}\n",
    "\n",
    "BiModelAttn_param = {\n",
    "    \"embed_size\": EMBED_DIM,\n",
    "    \"num_blocks\": 1,\n",
    "    \"num_heads\": 64,\n",
    "    \"drop_prob\": 0.1,\n",
    "    \"fusion_type\": \"add\"\n",
    "}\n",
    "\n",
    "shared_layer_param = {\n",
    "    \"in_dim\": EMBED_DIM,\n",
    "    \"hidden_dim\": [EMBED_DIM],\n",
    "    \"drop_prob\": 0.05,\n",
    "    \"BatchNorm\": False\n",
    "}\n",
    "\n",
    "DECODER_IN_DIM = int(EMBED_DIM*len(encoders_i) + EMBED_DIM*math.comb(len(encoders_i), 2))\n",
    "MLP_decoder_param = {\n",
    "    \"in_dim\": DECODER_IN_DIM,\n",
    "    \"out_dim\": targets_num,\n",
    "    \"hidden_dim\": [DECODER_IN_DIM//2],\n",
    "    \"drop_prob\": 0.1\n",
    "}\n",
    "\n",
    "collate_fn_params = [\n",
    "    {\"name\": basic_collate_fn.__name__},\n",
    "    {\"name\": basic_collate_fn.__name__},\n",
    "    {\"name\": tokens_batch.__name__, \"param\": {\"accum\": False, \"onset\": True}}\n",
    "]\n",
    "\n",
    "train_param = {\n",
    "    \"DATASET\": ecg_fusion_dataset_param,\n",
    "    \"MODEL_NAME\": \"ecg_fusion_unimodal\",\n",
    "    \"LAST\": only_last,\n",
    "    \"ENCODERS_I\": encoders_i,\n",
    "    \"ENCODERS_PARAM\": [ecg_sig_model_param, ecg_feats_model_param, ecg_note_model_param],\n",
    "    \"INTER_MODEL\": BiModalAttn.__name__,\n",
    "    \"INTER_MODEL_PARAM\": BiModelAttn_param,\n",
    "    \"SHARED_LAYER_PARAM\": shared_layer_param,\n",
    "    \"DECODER_MODEL\": MLPDecoderReg.__name__,\n",
    "    \"DECODER_PARAM\": MLP_decoder_param,\n",
    "    \"EMBED_DIM\": EMBED_DIM,\n",
    "    \"BATCH_SIZE\": 128,\n",
    "    \"LR\": 5E-05,\n",
    "    \"MAX_EPOCHS\": 20,\n",
    "    \"OPTIMIZER\": \"Adam\",\n",
    "    \"COLLATE_FN_PARAMS\": collate_fn_params\n",
    "}\n",
    "\n",
    "model = create_multimodal_model(train_param, device, k_models=k_models)\n",
    "\n",
    "collate_batch = CreateCustomDataset(len(collate_fn_params), train_param[\"COLLATE_FN_PARAMS\"], classfication=False)\n",
    "log = run_kfolds(train_param, model, ecg_fusion_dataset, ecg_sig_kfolds, log_folder=log_folder, collate_fun = collate_batch, classification=False)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchical Time-Aware Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_dataset = ecg.get_dataset(only_valid=True)\n",
    "ecg_dataset_param = {\n",
    "    \"path\": ecg_dataset_path,\n",
    "    \"only_valid\": True,\n",
    "    \"num\": len(ecg_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from datasets.collate_fun import CreateCustomDataset, ecg_bags_batch\n",
    "from blocks.mlp import MLP, MLPDecoderReg\n",
    "from models.unimodal import TemporalPooling\n",
    "from blocks.resnet import ResNet1d\n",
    "\n",
    "WIN_NUM = int(len(ecg.ecg_win_i))\n",
    "k_models = 5\n",
    "EMBED_DIM = 512\n",
    "\n",
    "TemporalPooling_param = {\n",
    "    \"model_path\": log_folder+\"/ecg_fusion_unimodal/.../\",\n",
    "    \"win_size\": WIN_NUM,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "embeds_model = torch.load(TemporalPooling_param[\"model_path\"]+\"model_0.pth\", weights_only=False)\n",
    "embeds_dim = embeds_model.shared_decoder.mlp[-1].in_features\n",
    "embeds_model.shared_decoder.mlp[-1] = nn.Identity()\n",
    "TemporalPooling_param[\"embeds_model\"] = embeds_model\n",
    "\n",
    "ResNet_param = {\n",
    "    \"input_dim\": (embeds_dim, WIN_NUM),\n",
    "    \"blocks_dim\": [(embeds_dim//2, 5)],\n",
    "    \"kernel_size\": 3,\n",
    "    \"dropout_rate\": 0.3\n",
    "}\n",
    "\n",
    "MLP_param = {\n",
    "    \"in_dim\": ResNet_param[\"blocks_dim\"][-1][0] * ResNet_param[\"blocks_dim\"][-1][1],\n",
    "    \"hidden_dim\": [EMBED_DIM],\n",
    "    \"drop_prob\": 0.05\n",
    "}\n",
    "\n",
    "MLP_decoder_param = {\n",
    "    \"in_dim\": EMBED_DIM,\n",
    "    \"out_dim\": targets_num,\n",
    "    \"hidden_dim\": [EMBED_DIM//2],\n",
    "    \"drop_prob\": 0.1\n",
    "}\n",
    "\n",
    "collate_fn_params = [{\"name\":ecg_bags_batch.__name__}]\n",
    "\n",
    "train_param = {\n",
    "    \"DATASET\": ecg_dataset_param,\n",
    "    \"MODEL_NAME\": \"ecg_unimodal\",\n",
    "    \"ENCODER_PARAM\": [TemporalPooling_param, ResNet_param, MLP_param],\n",
    "    \"ENCODER_MODEL\": [TemporalPooling.__name__, ResNet1d.__name__, MLP.__name__],\n",
    "    \"DECODER_PARAM\": MLP_decoder_param,\n",
    "    \"DECODER_MODEL\": MLPDecoderReg.__name__,\n",
    "    \"BATCH_SIZE\": 32,\n",
    "    \"LR\": 0.0005,\n",
    "    \"MAX_EPOCHS\": 20,\n",
    "    \"OPTIMIZER\": \"Adam\",\n",
    "    \"COLLATE_FN_PARAMS\": collate_fn_params\n",
    "}\n",
    "\n",
    "model = []\n",
    "if k_models is not None:\n",
    "    for mi in range(k_models):\n",
    "        embeds_model = torch.load(TemporalPooling_param[\"model_path\"]+\"model_%i.pth\"%(mi), weights_only=False)\n",
    "        embeds_model.shared_decoder.mlp[-1] = nn.Identity()\n",
    "        TemporalPooling_param[\"embeds_model\"] = embeds_model\n",
    "        \n",
    "        _model = create_unimodal_model(train_param[\"ENCODER_MODEL\"],\n",
    "                                    train_param[\"ENCODER_PARAM\"],\n",
    "                                    train_param[\"DECODER_MODEL\"],\n",
    "                                    train_param[\"DECODER_PARAM\"], device)\n",
    "        model.append(_model)\n",
    "else:   \n",
    "    model = create_unimodal_model(train_param[\"ENCODER_MODEL\"],\n",
    "                                    train_param[\"ENCODER_PARAM\"],\n",
    "                                    train_param[\"DECODER_MODEL\"],\n",
    "                                    train_param[\"DECODER_PARAM\"], device)\n",
    "\n",
    "del TemporalPooling_param[\"embeds_model\"]\n",
    "\n",
    "collate_batch = CreateCustomDataset(1, train_param[\"COLLATE_FN_PARAMS\"], classfication=False)\n",
    "\n",
    "log = run_kfolds(train_param, model, ecg_dataset, ecg_kfolds, collate_fun=collate_batch, log_folder=log_folder, classification=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
